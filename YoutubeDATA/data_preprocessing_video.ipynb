{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_gap_in_minutes(time_str):\n",
    "    print(time_str)\n",
    "    time_obj = datetime.fromisoformat(time_str[:-1])  # Remove the 'Z' suffix\n",
    "    now = datetime.now()\n",
    "    time_gap_seconds = (now - time_obj).total_seconds()\n",
    "    time_gap_minutes = round(time_gap_seconds / 60, 2)\n",
    "    return time_gap_minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 전처리 과정\n",
    "\n",
    "def video_preprocess(filename):\n",
    "    datas = pd.read_csv(f'./DATA/videos/{filename}.csv')\n",
    "    #YoutubeDATA\\DATA\\videos\\디글_호구들의감빵생활 레전드_20230401.csv\n",
    "    #C:\\Hallym\\Search\\YoutubeDATA\\DATA\\videos\\진격캐넌_단퐁회_20230408.csv\n",
    "    \n",
    "    datas = datas[datas.views != '-']\n",
    "    datas['views'] = datas['views'].astype(int)\n",
    "    datas\n",
    "\n",
    "    viewScaler = RobustScaler()\n",
    "    datas['views_scaled'] = viewScaler.fit_transform(datas['views'].to_numpy().reshape(-1,1))\n",
    "\n",
    "    likeScaler = RobustScaler()\n",
    "    # Scale the likes column, ignoring missing values\n",
    "    datas['likes_scaled'] = datas['likes']\n",
    "    datas.loc[datas['likes'].notnull(), 'likes_scaled'] = likeScaler.fit_transform(datas.loc[datas['likes'].notnull(), 'likes'].values.reshape(-1, 1))\n",
    "\n",
    "    # Replace missing values with -1\n",
    "    datas['likes_scaled'].fillna(-1, inplace=True)\n",
    "    \n",
    "    # calculate the date difference between rows\n",
    "    datas['update_diff'] = pd.to_datetime(datas['date'], format='%Y-%m-%dT%H:%M:%SZ').diff().apply(lambda x: x.total_seconds() / 3600)\n",
    "    datas['date'] = pd.to_datetime(datas['date'])\n",
    "    datas['time_gap_minutes'] = (pd.Timestamp.utcnow() - datas['date']).dt.total_seconds() / 60\n",
    "\n",
    "    # set the first date_diff value to 0\n",
    "    datas.loc[datas.index[0], 'update_diff'] = 0\n",
    "\n",
    "    datas['view_per_minutes'] = datas['views']/datas['time_gap_minutes']\n",
    "    # datas['likes_per_view'] = datas['likes'] / datas.loc[datas.index[0], 'views']\n",
    "    viewminScaler = RobustScaler()\n",
    "    datas['vpm_scaled'] = viewminScaler.fit_transform(datas['view_per_minutes'].to_numpy().reshape(-1,1))\n",
    "\n",
    "    datas.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "\n",
    "    datas.to_csv(f'./DATA/videos_preprocessed/{filename}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14F_4춘기_20230509.csv\n",
      "1theK_내돌투어_20230509.csv\n",
      "AI Jazeera English_Gold Mafia_20230509.csv\n",
      "AI Jazeera English_Inside Story_20230509.csv\n",
      "AJ_minecraft_20230509.csv\n",
      "Alessandra_Road to Eurovision_20230509.csv\n",
      "AOMG_막내84_20230509.csv\n",
      "Bangtan TV_슈취타_20230509.csv\n",
      "Be on Cloud_Be on Cloud Voyage_20230509.csv\n",
      "Be on Cloud_Be on Game_20230509.csv\n",
      "Colors of the Game_Colors of the Game_20230509.csv\n",
      "Curly Tales_The Legends_20230509.csv\n",
      "Davidsbeenhere_Kenya_20230509.csv\n",
      "DeeALup_Mass Effect Legendary Edition_20230509.csv\n",
      "Endless Adventure_50 state camper van road trip_20230509.csv\n",
      "EO_실리콘밸리댄스_20230509.csv\n",
      "GAMERIOT_CRIME BOSS ROCKAY CITY_20230509.csv\n",
      "GLITCH_MURDER DRONE_20230509.csv\n",
      "GoodTimewithScar_Limited Life_20230509.csv\n",
      "Grian_Limited Life_20230509.csv\n",
      "ImDontaiGaming_Resident Evil 4_20230509.csv\n",
      "IQ Gaming2_Multi Player_20230509.csv\n",
      "Jet Lag_New Zealand_20230509.csv\n",
      "Kara and Nate_Japan Travle Vlog_20230509.csv\n",
      "KBS Kpop_돌박이일_20230509.csv\n",
      "KBS Kpop_리무진서비스_20230509.csv\n",
      "KBS KPOP_아이돌 인간극장_20230509.csv\n",
      "KBS Kpop_은채의 스타일기_20230509.csv\n",
      "KCC_K씨씨대학교_20230509.csv\n",
      "KCC_프로출근러_20230509.csv\n",
      "Kobra Kids_Kobra Kids_20230509.csv\n",
      "Maria Clara e JP Games_Minecraft_20230509.csv\n",
      "Minutes of Sarith Surith_New Austrailia Tour_20230509.csv\n",
      "MovieHQ_Diable 4_20230509.csv\n",
      "MovieHQ_Hogwarts Legacy_20230509.csv\n",
      "Nugroho Febianto_Trip Ramadman_20230509.csv\n",
      "OOTB_전과자_20230509.csv\n",
      "Oxin Film_My Stroy the series_20230509.csv\n",
      "Patrick Mouratoglou_TENISS MASTERCLASS_20230509.csv\n",
      "PearlscentMoon_Limited Life_20230509.csv\n",
      "Sailing SV Delos_Boar yard series in Mexico_20230509.csv\n",
      "Samuel and Audrey_Renovating hotel in Argentina_20230509.csv\n",
      "SmallishBeans_Limited Life_20230509.csv\n",
      "Stray Kids_SKZ Code_20230509.csv\n",
      "TencentVideo_My Little Doctor_20230509.csv\n",
      "theRadBrad_dead island 2_20230509.csv\n",
      "TheRadBrad_Resident Evil 4_20230509.csv\n",
      "theRadBrad_Star Wars Jedai Survivor_20230509.csv\n",
      "Thumbs up Austrailia_VANDAYZ_20230509.csv\n",
      "TmarTn2_MLB 23_20230509.csv\n",
      "Toogii_Cafeowner Simulator_20230509.csv\n",
      "Toogii_Hogwarts Legacy_20230509.csv\n",
      "Tsar FC_FIFA 23_20230509.csv\n",
      "UDONSOBA OSAKA NARA_Chinese_20230509.csv\n",
      "UDONSOBA OSAKA NARA_OSAKA_20230509.csv\n",
      "Vanwives Pack Chat_Watch from the start_20230509.csv\n",
      "WildLens_Inda_20230509.csv\n",
      "WINNER_WINNER BROTHERS_20230509.csv\n",
      "WIRED_Autocomplete Interview_20230509.csv\n",
      "YAMAHA Motors USA_Beyond the Gate_20230509.csv\n",
      "Yash_Yash vs Vultus_20230509.csv\n",
      "Yuewen Animation_무동건곤_20230509.csv\n",
      "Yuewen Animation_전업법사_20230509.csv\n",
      "Zahait_Masterplan Tycoon_20230509.csv\n",
      "강형욱의 보듬TV_견종백과_20230509.csv\n",
      "겁도 없꾸라_겁도 없꾸라_20230509.csv\n",
      "공부왕찐천재 홍진경_수업시간_20230509.csv\n",
      "곽튜브_찐따록_20230509.csv\n",
      "괴물쥐_악어의 놀이터_20230509.csv\n",
      "글자네_단퐁회_20230509.csv\n",
      "김줄스_2023 가물치 연못_20230509.csv\n",
      "김지윤의 지식play_국제정치_20230509.csv\n",
      "김한강_김한강 시리즈_20230509.csv\n",
      "꼰대희_밥묵자_20230509.csv\n",
      "끄적끄적_끄적끄적_20230509.csv\n",
      "낄낄상회_가졳같은회사_20230509.csv\n",
      "낄낄상회_자취기생충_20230509.csv\n",
      "너덜트_너덜트_20230509.csv\n",
      "달라스튜디오_네고왕_20230509.csv\n",
      "대교 써밋_4교시에 갇혔다_20230509.csv\n",
      "도모다찌_도모다찌_20230509.csv\n",
      "독일사냥꾼_스코틀랜드 사냥_20230509.csv\n",
      "동수칸_악어의 놀이터_20230509.csv\n",
      "딥필름_장기연애_20230509.csv\n",
      "따구_브라질_20230509.csv\n",
      "뜬뜬_빰빰소셜클럽_20230509.csv\n",
      "뜬뜬_핑계고_20230509.csv\n",
      "라이프에이드_수면게임_20230509.csv\n",
      "르세라핌_LENIVERSE_20230509.csv\n",
      "명예훈장_단퐁회_20230509.csv\n",
      "몬스타X_몬 먹어도 고_20230509.csv\n",
      "빠더너스_오지않는당신을기다리며3_20230509.csv\n",
      "성시경_먹을텐데_20230509.csv\n",
      "스낵타운_엘프타운_20230509.csv\n",
      "스튜디오 와플_바퀴달린입3_20230509.csv\n",
      "스튜디오 피넛버터_전부 노래 잘함_20230509.csv\n",
      "시즌비시즌_시즌3_20230509.csv\n",
      "악어_악어의 놀이터_20230509.csv\n",
      "용진호건강원_용진호건강원_20230509.csv\n",
      "워크맨_워크맨2_20230509.csv\n",
      "이지금_아이유의팔레트_20230509.csv\n",
      "재밌는 거 올라온다_또간집_20230509.csv\n",
      "제일기획_제일엔터테인먼트_20230509.csv\n",
      "조현아_조현아의 목요일 밤_20230509.csv\n",
      "지켜츄_지켜츄_20230509.csv\n",
      "진격캐넌_단퐁회_20230509.csv\n",
      "차린건 쥐뿔도 없지만_차린건 쥐뿔도 없지만_20230509.csv\n",
      "채코제_아메리카 여행_20230509.csv\n",
      "춘자_단퐁회_20230509.csv\n",
      "캡존탁_단퐁회_20230509.csv\n",
      "쿠첸_먹어BAR_20230509.csv\n",
      "파뿌리_천원vs만원vs천만원_20230509.csv\n",
      "팡이요_단퐁회_20230509.csv\n",
      "피식대학_05학번이즈히어_20230509.csv\n",
      "피식대학_PSICK SHOW_20230509.csv\n",
      "하나은행_돈을말하다_20230509.csv\n",
      "하이틴에이저_애들연애_20230509.csv\n",
      "하이틴에이저_웹드라마_20230509.csv\n",
      "홍쓴tv_vlog_20230509.csv\n"
     ]
    }
   ],
   "source": [
    "path = r\".\\DATA\\videos\"\n",
    "file_lst = os.listdir(path)\n",
    "\n",
    "for filename in file_lst:\n",
    "    print(filename)\n",
    "    video_preprocess(filename[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv('./DATA/PopularRightNow/PRN_korea_20230402.csv')\n",
    "\n",
    "# create a new DataFrame by exploding the 'tags' column\n",
    "tags_df = df.explode('tags')\n",
    "\n",
    "# group by 'tags' and aggregate the sum of 'views' and count of 'tags'\n",
    "result = tags_df.groupby('tags').agg({'views': 'sum', 'tags': 'count'})\n",
    "\n",
    "# rename the columns to more descriptive names\n",
    "result = result.rename(columns={'tags': 'tag_count', 'views': 'total_views'})\n",
    "\n",
    "# sort the DataFrame by 'total_views' in descending order\n",
    "result = result.sort_values('total_views', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   tag  count\n",
      "0     YG Entertainment      2\n",
      "1                   YG      3\n",
      "2                  와이지      2\n",
      "3                K-pop      2\n",
      "4            BLACKPINK      1\n",
      "...                ...    ...\n",
      "2948               다이닝      1\n",
      "2949            미쉐린가이드      1\n",
      "2950               미쉐린      1\n",
      "2951          michelin      1\n",
      "2952             seoul      1\n",
      "\n",
      "[2953 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# parse the \"tags\" column as a list of strings\n",
    "df['tags'] = df['tags'].apply(lambda x: ast.literal_eval(x) if x != 'Nan' else np.nan)\n",
    "\n",
    "# drop rows with NaN values in the \"tags\" column\n",
    "df = df.dropna(subset=['tags'])\n",
    "\n",
    "# create a list of all tags in the DataFrame\n",
    "tag_list = [tag for sublist in df['tags'] for tag in sublist]\n",
    "\n",
    "# create a dictionary to store the value counts\n",
    "value_counts = {}\n",
    "\n",
    "# iterate over each value in the tag list\n",
    "for value in tag_list:\n",
    "    # add the value to the dictionary with a count of 1 if it does not already exist, or increment its count if it does\n",
    "    value_counts[value] = value_counts.get(value, 0) + 1\n",
    "\n",
    "# create a DataFrame from the dictionary of value counts\n",
    "df_counts = pd.DataFrame(list(value_counts.items()), columns=['tag', 'count'])\n",
    "\n",
    "# print the result\n",
    "print(df_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['YG Entertainment',\n",
       " 'YG',\n",
       " '와이지',\n",
       " 'K-pop',\n",
       " 'BLACKPINK',\n",
       " '블랙핑크',\n",
       " '블핑',\n",
       " '제니',\n",
       " '로제',\n",
       " '리사',\n",
       " '지수',\n",
       " 'LISA',\n",
       " 'JISOO',\n",
       " 'JENNIE',\n",
       " 'ROSÉ',\n",
       " 'BLINK',\n",
       " '블링크',\n",
       " '지수 꽃',\n",
       " 'JISOO FLOWER',\n",
       " 'FLOWER',\n",
       " 'All Eyes On Me',\n",
       " 'JISOO All Eyes On Me',\n",
       " '지수 All Eyes On Me',\n",
       " 'JISOO ME',\n",
       " 'ME',\n",
       " '지수 FLOWER',\n",
       " 'JISOO 꽃']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "my_list = ast.literal_eval(df['tags'][0])\n",
    "\n",
    "my_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1016dafd80048a904a2cf3599b8e35f3e8043a2e69ac88becd2cce80983c1a05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
