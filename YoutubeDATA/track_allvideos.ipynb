{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from oauth2client.tools import argparser\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_duration(duration):\n",
    "    \"\"\"Parse a duration string in ISO 8601 format and return the number of seconds.\"\"\"\n",
    "    match = re.match(r\"PT(\\d+H)?(\\d+M)?(\\d+S)?\", duration)\n",
    "    hours = int(match.group(1)[:-1]) if match.group(1) else 0\n",
    "    minutes = int(match.group(2)[:-1]) if match.group(2) else 0\n",
    "    seconds = int(match.group(3)[:-1]) if match.group(3) else 0\n",
    "    return hours * 3600 + minutes * 60 + seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_gap_in_hours(time_str):\n",
    "    time_obj = datetime.fromisoformat(time_str[:-1])  # Remove the 'Z' suffix\n",
    "    now = datetime.now()\n",
    "    time_gap_seconds = (now - time_obj).total_seconds()\n",
    "    time_gap_hours = round(time_gap_seconds / 3600, 2)\n",
    "    return time_gap_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statics(datas,channelId,playlistName):\n",
    "    category_id=[]\n",
    "    views=[]\n",
    "    likes=[]\n",
    "    favorites = []\n",
    "    comments=[]\n",
    "    title=[]\n",
    "    date=[]\n",
    "    date_gap=[]\n",
    "    duration=[]\n",
    "    tag=[]\n",
    "    id=[]\n",
    "\n",
    "    for i in range(len(datas)):\n",
    "        request=youtube.videos().list(\n",
    "        part='snippet,statistics,contentDetails',\n",
    "        id=datas['video_id'][i],\n",
    "        maxResults=100)\n",
    "        \n",
    "        response=request.execute()\n",
    "        id.append(datas['video_id'][i])\n",
    "        \n",
    "        if response['items']==[]:\n",
    "            title.append('-')\n",
    "            category_id.append('-')\n",
    "            views.append('-')\n",
    "            likes.append('-')\n",
    "            favorites.append('-')\n",
    "            comments.append('-')\n",
    "            date.append('-')\n",
    "            date_gap.append('-')\n",
    "            duration.append('-')\n",
    "            tag.append('-')\n",
    "            \n",
    "        else :\n",
    "            title.append(response['items'][0]['snippet']['title'].replace(',',' ').replace('|',' '))\n",
    "            category_id.append(response['items'][0]['snippet']['categoryId'])\n",
    "            views.append(response['items'][0]['statistics']['viewCount'])\n",
    "            if 'likeCount' in response['items'][0]['statistics']:\n",
    "                likes.append(response['items'][0]['statistics']['likeCount'])\n",
    "            else:\n",
    "                likes.append('NaN')\n",
    "            favorites.append(response['items'][0]['statistics']['favoriteCount'])\n",
    "            if 'comments' in response['items'][0]['statistics']:\n",
    "                comments.append(response['items'][0]['statistics']['commentCount'])\n",
    "            else:\n",
    "                comments.append('NaN')\n",
    "            date.append(response['items'][0]['snippet']['publishedAt'])\n",
    "            date_gap.append(get_time_gap_in_hours(response['items'][0]['snippet']['publishedAt']))\n",
    "            duration.append(parse_duration(response['items'][0]['contentDetails']['duration']))\n",
    "            if 'tags' in response['items'][0]['snippet']:\n",
    "                tag.append(response['items'][0]['snippet']['tags'])\n",
    "            else:\n",
    "                tag.append('NaN')\n",
    "            \n",
    "        \n",
    "    df=pd.DataFrame([id,title,category_id,views,likes,favorites,comments,date,date_gap,duration,tag]).T\n",
    "    df.columns=['id','title','category_id','views','likes','favorites','comments','date','date_gap','duration','tags']\n",
    "    df.sort_values(by=['date'],inplace=True)\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    today = datetime.today()\n",
    "\n",
    "    currentDay = today.strftime(\"%Y%m%d\")\n",
    "\n",
    "    df.to_csv(f'./DATA/videos/{channelId}_{playlistName}_{currentDay}.csv', sep=',', na_rep='NaN')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BANGTANTV_Run BTS! Episode 1~40.csv\n",
      "BANGTANTV_Run BTS! Episode 41~80.csv\n",
      "BANGTANTV_Run BTS! Episode 81~120.csv\n",
      "EBS 키즈_곰디와 친구들.csv\n",
      "JTBC Voyage_비정상회담.csv\n",
      "KBS Joy_[무엇이든 물어보살] 신통방통 리얼 고민 해결쇼 2022.csv\n",
      "MBC 미스터리_[어둑시니pick 시즌1].csv\n",
      "MBC 미스터리_[어둑시니pick 시즌2].csv\n",
      "odg_ODG X Artist.csv\n",
      "tvN_강식당1.csv\n",
      "tvN_파트너게임.csv\n",
      "감스트_손흥민 키우기.csv\n",
      "감스트_열끼니.csv\n",
      "감스트_위닝2019.csv\n",
      "강형욱의 보듬TV_견종백과.csv\n",
      "공부왕찐천재 홍진경_수업시간.csv\n",
      "곽튜브_세계여행(2021).csv\n",
      "글자네_단퐁회.csv\n",
      "김한강_김한강 시리즈.csv\n",
      "꼰대희_밥묵자.csv\n",
      "녹두로_마인크래프트.csv\n",
      "녹두로_몬스터헌터 선브.csv\n",
      "녹두로_테라리아.csv\n",
      "녹두로_포켓몬스바.csv\n",
      "달라스튜디오_네고왕.csv\n",
      "대암씨_더포레스트.csv\n",
      "대암씨_데빌메이크라이.csv\n",
      "대암씨_돈스타브.csv\n",
      "대암씨_로보토미.csv\n",
      "대암씨_몬스터헌터 월드.csv\n",
      "대암씨_새티스팩토리.csv\n",
      "대암씨_슬라임랜처.csv\n",
      "대암씨_테라리아.csv\n",
      "대암씨_픽스아크.csv\n",
      "대암씨_할로우나이트.csv\n",
      "디글_사랑의불시착.csv\n",
      "디글_악의꽃.csv\n",
      "디글_호구들의감빵생활 레전드.csv\n",
      "디글_호텔델루나.csv\n",
      "딩고스토리_mbti love.csv\n",
      "딩고스토리_라이크.csv\n",
      "딩고스토리_썰스데이1.csv\n",
      "딩고스토리_썰스데이2.csv\n",
      "딩고스토리_썰스데이3.csv\n",
      "딩고스토리_썸남.csv\n",
      "딩고스토리_엘턴십.csv\n",
      "명예훈장_단퐁회.csv\n",
      "빠니보틀_아메리카여행.csv\n",
      "빠니보틀_유라시아 여행.csv\n",
      "빽능_X맨.csv\n",
      "빽능_불타는 청춘.csv\n",
      "빽능_패밀리가 떴다.csv\n",
      "사피엔스 스튜디오_벌거벗은세계사.csv\n",
      "사피엔스 스튜디오_벌거벗은한국사.csv\n",
      "삼성전자 반도체 뉴스룸_S로그.csv\n",
      "새덕후_야생동물구조센터.csv\n",
      "수제비_두음쌤2023.csv\n",
      "스튜디오 와플_바퀴달린입1.csv\n",
      "스튜디오 와플_바퀴달린입2.csv\n",
      "스튜디오 와플_바퀴달린입3.csv\n",
      "스튜디오 와플_터키즈.csv\n",
      "스튜디오 피넛버터_전부 노래 잘함.csv\n",
      "승우아빠_같이한끼.csv\n",
      "승우아빠_경력있는막내.csv\n",
      "승우아빠_경력있는신입.csv\n",
      "승우아빠_셰프의 시그니처.csv\n",
      "시즌비시즌_구독자가 시키면 뭐든지 다 함.csv\n",
      "시즌비시즌_시즌2.csv\n",
      "시즌비시즌_시즌3.csv\n",
      "쏘이_몰타 여행.csv\n",
      "엠뚜루마뚜루_태어난김에 세계일주.csv\n",
      "여행가 제이_chapter1.csv\n",
      "여행가 제이_chapter2.csv\n",
      "여행가 제이_chapter3.csv\n",
      "여행가 제이_chapter5.csv\n",
      "옥냥이_로스트아크.csv\n",
      "우왁굳_아르마3 랜덤고지전.csv\n",
      "우왁굳_용과같이7.csv\n",
      "이과장_좋좋소.csv\n",
      "장지수_공범.csv\n",
      "재밌는 거 올라온다_또간집.csv\n",
      "조코딩_좋코딩.csv\n",
      "지켜츄_지켜츄.csv\n",
      "진격캐넌_단퐁회.csv\n",
      "쫑쫑걸음_탄자니아.csv\n",
      "차린건 쥐뿔도 없지만_차린건 쥐뿔도 없지만.csv\n",
      "차박차박_[시즌3] 그냥걷자 세계여행.csv\n",
      "채널 십오야_신서유기8.csv\n",
      "채널십오야_악마는정남이를 입는다.csv\n",
      "채코제_아메리카 여행.csv\n",
      "채코제_아시아 여행.csv\n",
      "체코제_아메리카 여행.csv\n",
      "체코제_유럽 여행.csv\n",
      "춘자_단퐁회.csv\n",
      "춘천MBC 프로그램_가고잡소.csv\n",
      "춘천시_[또무관TV].csv\n",
      "캐럿맨 여행기_터키 TR.csv\n",
      "캡존탁_단퐁회.csv\n",
      "팡이요_단퐁회.csv\n",
      "플레이스트 오리지널_에이틴1.csv\n",
      "플레이스트 오리지널_연플리 몰아보기.csv\n",
      "플레이애니_마음의 소리.csv\n",
      "플레이애니_빼꼼 시즌1.csv\n",
      "플레이애니_빼꼼 시즌2.csv\n",
      "플레이애니_빼꼼 시즌3.csv\n",
      "플레이애니_아기공룡 둘리.csv\n",
      "할명수_할명수 시즌1.csv\n",
      "해커스톡_비타민 영어.csv\n",
      "황선생 기타교실_오늘은 우쿨렐레.csv\n"
     ]
    }
   ],
   "source": [
    "path = \".\\DATA\\ids\\ed\"\n",
    "file_lst = os.listdir(path)\n",
    "f = open(\"key.txt\",'r')\n",
    "DEVELOPER_KEY= f.readline()\n",
    "f.close()\n",
    "\n",
    "YOUTUBE_API_SERVICE_NAME='youtube'\n",
    "YOUTUBE_API_VERSION='v3'\n",
    "\n",
    "youtube=build(YOUTUBE_API_SERVICE_NAME,YOUTUBE_API_VERSION,developerKey=DEVELOPER_KEY)\n",
    "\n",
    "for filename in file_lst:\n",
    "    datas = pd.read_csv(f\".\\DATA\\ids\\ed\\{filename}\")\n",
    "    print(filename)\n",
    "    channelId, playlistName = filename[:-4].split('_')\n",
    "    get_statics(datas,channelId, playlistName)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youtube",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "03620e9787172838262168b97c55377c28b63e01501a24e458c708380ad6f3a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
